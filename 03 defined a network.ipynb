{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define a net-- LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([6, 1, 3, 3])\n",
      "conv1.bias : torch.Size([6])\n",
      "conv2.weight : torch.Size([16, 6, 3, 3])\n",
      "conv2.bias : torch.Size([16])\n",
      "fc1.weight : torch.Size([120, 576])\n",
      "fc1.bias : torch.Size([120])\n",
      "fc2.weight : torch.Size([84, 120])\n",
      "fc2.bias : torch.Size([84])\n",
      "fc3.weight : torch.Size([10, 84])\n",
      "fc3.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name,parameters in net.named_parameters():\n",
    "    print(name,':',parameters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-0.3205, -0.1745,  0.1085],\n",
       "           [ 0.2516, -0.2107, -0.0206],\n",
       "           [ 0.2595,  0.2865, -0.2976]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2556, -0.2376,  0.1733],\n",
       "           [-0.1275, -0.0442, -0.3245],\n",
       "           [-0.2551, -0.2797, -0.3171]]],\n",
       " \n",
       " \n",
       "         [[[-0.2548,  0.3278,  0.0873],\n",
       "           [ 0.0344,  0.0687, -0.2093],\n",
       "           [ 0.0934, -0.3255, -0.2809]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0131, -0.2448,  0.0323],\n",
       "           [-0.0572,  0.0250,  0.0201],\n",
       "           [-0.2382,  0.0284,  0.2721]]],\n",
       " \n",
       " \n",
       "         [[[-0.0984, -0.2502, -0.2742],\n",
       "           [-0.1103,  0.1118,  0.0399],\n",
       "           [-0.2475, -0.1893,  0.0051]]],\n",
       " \n",
       " \n",
       "         [[[-0.2054, -0.2294,  0.0654],\n",
       "           [ 0.0239, -0.1071,  0.0255],\n",
       "           [-0.0897,  0.0576,  0.0373]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2785,  0.3038, -0.2244, -0.0777,  0.1916,  0.2181],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0971,  0.0744, -0.0232],\n",
       "           [-0.0112,  0.0911,  0.0139],\n",
       "           [-0.1289,  0.0168, -0.0955]],\n",
       " \n",
       "          [[ 0.0090, -0.1249, -0.0390],\n",
       "           [-0.0108, -0.0356, -0.0198],\n",
       "           [ 0.0096,  0.0359, -0.1175]],\n",
       " \n",
       "          [[ 0.0463,  0.1213, -0.0196],\n",
       "           [-0.1050, -0.0905,  0.1313],\n",
       "           [-0.0116, -0.0504, -0.0512]],\n",
       " \n",
       "          [[-0.0945, -0.1236,  0.1306],\n",
       "           [-0.0418, -0.0828, -0.1011],\n",
       "           [-0.0532, -0.1144, -0.0364]],\n",
       " \n",
       "          [[ 0.0658, -0.0283,  0.0164],\n",
       "           [-0.0043, -0.0775,  0.0112],\n",
       "           [ 0.1335, -0.0101, -0.0194]],\n",
       " \n",
       "          [[-0.1166, -0.1041,  0.1078],\n",
       "           [-0.0816, -0.0805,  0.0422],\n",
       "           [ 0.0663,  0.0207, -0.0604]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0902,  0.0233, -0.1233],\n",
       "           [ 0.0998, -0.0494,  0.1174],\n",
       "           [ 0.0509, -0.0250,  0.0442]],\n",
       " \n",
       "          [[-0.0362, -0.0266,  0.0197],\n",
       "           [ 0.0577, -0.0911,  0.0131],\n",
       "           [ 0.0831,  0.0329,  0.0313]],\n",
       " \n",
       "          [[-0.0739, -0.0756, -0.1297],\n",
       "           [ 0.0100,  0.0806, -0.0722],\n",
       "           [-0.0040, -0.1179, -0.1077]],\n",
       " \n",
       "          [[ 0.0154,  0.0030,  0.0199],\n",
       "           [-0.1079,  0.0668,  0.0143],\n",
       "           [-0.0294,  0.0272,  0.0869]],\n",
       " \n",
       "          [[-0.1144, -0.0666,  0.1180],\n",
       "           [-0.0127, -0.0533, -0.0138],\n",
       "           [ 0.1055,  0.1040, -0.0761]],\n",
       " \n",
       "          [[ 0.1222, -0.0662, -0.0097],\n",
       "           [-0.1342,  0.0441, -0.0620],\n",
       "           [-0.1360, -0.1222, -0.0815]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1024, -0.0682, -0.0496],\n",
       "           [ 0.0579,  0.0111, -0.0249],\n",
       "           [-0.0736,  0.0967,  0.0789]],\n",
       " \n",
       "          [[ 0.1215,  0.0509, -0.0340],\n",
       "           [-0.0218, -0.0384, -0.0184],\n",
       "           [ 0.0417,  0.0321, -0.1215]],\n",
       " \n",
       "          [[ 0.0440,  0.0563, -0.0271],\n",
       "           [-0.0593, -0.1319, -0.0500],\n",
       "           [ 0.0565,  0.0827,  0.0680]],\n",
       " \n",
       "          [[-0.0017,  0.1100, -0.0749],\n",
       "           [ 0.0222,  0.0392, -0.0758],\n",
       "           [-0.1217, -0.0431, -0.0430]],\n",
       " \n",
       "          [[-0.0084, -0.1330, -0.0159],\n",
       "           [ 0.1303,  0.1257, -0.0415],\n",
       "           [ 0.0343, -0.0520,  0.0709]],\n",
       " \n",
       "          [[-0.0360, -0.0904,  0.0504],\n",
       "           [-0.0780,  0.0359, -0.0507],\n",
       "           [ 0.0258,  0.1040, -0.0896]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0026, -0.0591,  0.0684],\n",
       "           [ 0.1013, -0.0137,  0.0483],\n",
       "           [-0.1008,  0.0703,  0.0552]],\n",
       " \n",
       "          [[-0.0272, -0.0138,  0.0434],\n",
       "           [-0.0048, -0.0175,  0.0681],\n",
       "           [-0.0846,  0.0786, -0.1102]],\n",
       " \n",
       "          [[-0.0936, -0.0438,  0.0482],\n",
       "           [-0.0141, -0.1284, -0.0484],\n",
       "           [-0.0035,  0.0628, -0.0158]],\n",
       " \n",
       "          [[ 0.1257,  0.1221,  0.1243],\n",
       "           [ 0.0349, -0.1101,  0.0035],\n",
       "           [-0.1327, -0.1304, -0.0892]],\n",
       " \n",
       "          [[ 0.1052, -0.0834,  0.0183],\n",
       "           [ 0.1135,  0.0916,  0.0978],\n",
       "           [ 0.0659,  0.0206,  0.0619]],\n",
       " \n",
       "          [[ 0.0199, -0.0505, -0.0502],\n",
       "           [-0.0981,  0.0053,  0.0184],\n",
       "           [-0.1266, -0.0290, -0.1082]]],\n",
       " \n",
       " \n",
       "         [[[-0.0187, -0.1268, -0.0491],\n",
       "           [-0.1167, -0.0585,  0.1226],\n",
       "           [-0.0249, -0.1176, -0.0708]],\n",
       " \n",
       "          [[-0.1293,  0.0238, -0.0636],\n",
       "           [-0.0661,  0.0561, -0.0524],\n",
       "           [ 0.1307, -0.0979, -0.0011]],\n",
       " \n",
       "          [[ 0.0761, -0.1359, -0.0749],\n",
       "           [-0.0371, -0.0343, -0.0935],\n",
       "           [-0.0178, -0.1329, -0.0716]],\n",
       " \n",
       "          [[-0.0920, -0.0825, -0.1146],\n",
       "           [ 0.0924, -0.1090, -0.1333],\n",
       "           [ 0.0907,  0.0956, -0.0706]],\n",
       " \n",
       "          [[-0.0040,  0.0380, -0.0695],\n",
       "           [-0.0187,  0.0715, -0.1335],\n",
       "           [ 0.0391, -0.1141,  0.0703]],\n",
       " \n",
       "          [[-0.0769, -0.0250,  0.0063],\n",
       "           [-0.0279,  0.0791,  0.0999],\n",
       "           [ 0.0348,  0.1124,  0.0389]]],\n",
       " \n",
       " \n",
       "         [[[-0.0718,  0.0343,  0.1172],\n",
       "           [ 0.0770, -0.0331,  0.1086],\n",
       "           [ 0.0896,  0.1303, -0.1295]],\n",
       " \n",
       "          [[ 0.0059, -0.1097,  0.1216],\n",
       "           [-0.0107,  0.0103, -0.1055],\n",
       "           [ 0.0621,  0.0937, -0.0385]],\n",
       " \n",
       "          [[-0.0283,  0.0440, -0.0126],\n",
       "           [-0.0901, -0.0657, -0.1209],\n",
       "           [-0.1046,  0.1164,  0.0504]],\n",
       " \n",
       "          [[ 0.1257,  0.1053,  0.0504],\n",
       "           [ 0.1302,  0.0018, -0.0844],\n",
       "           [ 0.1243, -0.0776, -0.0618]],\n",
       " \n",
       "          [[ 0.0559,  0.0902, -0.0023],\n",
       "           [-0.0843,  0.0254, -0.0135],\n",
       "           [-0.1221,  0.0378, -0.0603]],\n",
       " \n",
       "          [[ 0.0285,  0.1151, -0.0505],\n",
       "           [ 0.0971, -0.0114,  0.0866],\n",
       "           [ 0.0055, -0.0938,  0.0302]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0020, -0.0629,  0.0336],\n",
       "           [-0.0398, -0.1225,  0.1090],\n",
       "           [-0.0325,  0.0603, -0.0655]],\n",
       " \n",
       "          [[ 0.0168,  0.0765,  0.0708],\n",
       "           [-0.0743,  0.0309,  0.0342],\n",
       "           [ 0.0261, -0.0373,  0.1139]],\n",
       " \n",
       "          [[-0.1341,  0.0357, -0.0980],\n",
       "           [-0.0699,  0.0418,  0.0889],\n",
       "           [-0.1280, -0.0092,  0.0246]],\n",
       " \n",
       "          [[-0.0317, -0.1256,  0.1346],\n",
       "           [ 0.0871,  0.0961, -0.0413],\n",
       "           [-0.0723, -0.0248, -0.0686]],\n",
       " \n",
       "          [[ 0.0205,  0.0648,  0.0689],\n",
       "           [-0.1286, -0.0946,  0.0520],\n",
       "           [-0.0591, -0.0948,  0.0274]],\n",
       " \n",
       "          [[ 0.1034, -0.0471,  0.0476],\n",
       "           [ 0.0551, -0.0296,  0.0797],\n",
       "           [ 0.0171,  0.1283, -0.0461]]],\n",
       " \n",
       " \n",
       "         [[[-0.0403, -0.0757,  0.0659],\n",
       "           [ 0.0513,  0.1093,  0.0546],\n",
       "           [ 0.1223,  0.0587, -0.0836]],\n",
       " \n",
       "          [[ 0.0637, -0.1302,  0.0511],\n",
       "           [ 0.0351, -0.0235,  0.0894],\n",
       "           [ 0.0262,  0.1304, -0.0548]],\n",
       " \n",
       "          [[-0.1011, -0.0523, -0.0107],\n",
       "           [-0.0529,  0.0409, -0.0468],\n",
       "           [-0.0239,  0.0591,  0.0095]],\n",
       " \n",
       "          [[ 0.0330, -0.0269,  0.0720],\n",
       "           [-0.0135, -0.0884, -0.0914],\n",
       "           [ 0.0703, -0.0004,  0.0448]],\n",
       " \n",
       "          [[-0.0996,  0.0623, -0.0384],\n",
       "           [ 0.1275, -0.0302,  0.0493],\n",
       "           [-0.0188, -0.0045, -0.0409]],\n",
       " \n",
       "          [[-0.0441, -0.0396,  0.0931],\n",
       "           [-0.0112, -0.0565,  0.0902],\n",
       "           [ 0.0417,  0.0307, -0.1181]]],\n",
       " \n",
       " \n",
       "         [[[-0.1337, -0.0585,  0.1114],\n",
       "           [ 0.0075, -0.0596,  0.0086],\n",
       "           [-0.1164,  0.0741, -0.0498]],\n",
       " \n",
       "          [[-0.0689,  0.1019, -0.0178],\n",
       "           [ 0.0328, -0.1025,  0.0415],\n",
       "           [ 0.0144, -0.0624,  0.0158]],\n",
       " \n",
       "          [[-0.1052, -0.0443, -0.0609],\n",
       "           [ 0.0463, -0.0343, -0.0083],\n",
       "           [-0.0676,  0.0720,  0.0413]],\n",
       " \n",
       "          [[ 0.0764,  0.0254, -0.0302],\n",
       "           [-0.0647, -0.0936,  0.0291],\n",
       "           [ 0.0037, -0.0638,  0.0853]],\n",
       " \n",
       "          [[ 0.0549,  0.1040, -0.0618],\n",
       "           [ 0.0941, -0.0072, -0.0440],\n",
       "           [-0.0971, -0.1197,  0.0888]],\n",
       " \n",
       "          [[-0.0605, -0.0777, -0.0205],\n",
       "           [-0.0568,  0.0241,  0.0514],\n",
       "           [ 0.0959, -0.0510, -0.0714]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0806, -0.1060,  0.0327],\n",
       "           [-0.1257,  0.0773,  0.0214],\n",
       "           [-0.1326, -0.0599,  0.0751]],\n",
       " \n",
       "          [[-0.1151,  0.0283,  0.1242],\n",
       "           [-0.1215,  0.0342, -0.1154],\n",
       "           [ 0.1312, -0.0001,  0.0453]],\n",
       " \n",
       "          [[ 0.1091,  0.0043,  0.0243],\n",
       "           [-0.0223,  0.0498,  0.1059],\n",
       "           [ 0.0976,  0.0841, -0.1132]],\n",
       " \n",
       "          [[-0.0856, -0.0247,  0.0710],\n",
       "           [-0.1123,  0.0513,  0.0622],\n",
       "           [ 0.1135, -0.0487, -0.1229]],\n",
       " \n",
       "          [[ 0.0109, -0.0500, -0.0625],\n",
       "           [ 0.0645, -0.0346,  0.1052],\n",
       "           [-0.0864,  0.0021, -0.0553]],\n",
       " \n",
       "          [[-0.0455,  0.0932, -0.0532],\n",
       "           [-0.0545, -0.1288, -0.1153],\n",
       "           [-0.1064, -0.0279,  0.0387]]],\n",
       " \n",
       " \n",
       "         [[[-0.0150,  0.0718, -0.0955],\n",
       "           [-0.0243, -0.0860,  0.0455],\n",
       "           [-0.0546,  0.0931,  0.0446]],\n",
       " \n",
       "          [[ 0.0448,  0.0382,  0.1264],\n",
       "           [ 0.1332,  0.0187,  0.1113],\n",
       "           [-0.1097, -0.0789, -0.1294]],\n",
       " \n",
       "          [[-0.0461,  0.1129,  0.1308],\n",
       "           [-0.0919,  0.0588, -0.0241],\n",
       "           [ 0.0426,  0.0648, -0.1173]],\n",
       " \n",
       "          [[-0.1216, -0.0661,  0.0919],\n",
       "           [-0.0007,  0.0913, -0.0490],\n",
       "           [ 0.0306, -0.1098,  0.0034]],\n",
       " \n",
       "          [[ 0.0777, -0.0595,  0.0804],\n",
       "           [-0.0137,  0.0438,  0.1174],\n",
       "           [-0.0430, -0.1344, -0.1107]],\n",
       " \n",
       "          [[ 0.0630, -0.0962, -0.0382],\n",
       "           [ 0.0784,  0.0763, -0.0961],\n",
       "           [-0.1164,  0.0424,  0.1308]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0667,  0.1000,  0.1002],\n",
       "           [-0.0501, -0.1358,  0.0670],\n",
       "           [-0.0962, -0.0955, -0.1317]],\n",
       " \n",
       "          [[ 0.0946, -0.0083,  0.0807],\n",
       "           [-0.1129, -0.0257, -0.0839],\n",
       "           [ 0.0169,  0.1247,  0.0225]],\n",
       " \n",
       "          [[-0.0710,  0.0704, -0.0360],\n",
       "           [-0.0581,  0.0389, -0.1142],\n",
       "           [-0.0363,  0.0644,  0.0726]],\n",
       " \n",
       "          [[-0.0545, -0.0033,  0.1140],\n",
       "           [ 0.0848, -0.1087,  0.0141],\n",
       "           [ 0.0677, -0.0439,  0.0855]],\n",
       " \n",
       "          [[ 0.1104, -0.0187,  0.0496],\n",
       "           [ 0.0175,  0.0700,  0.1246],\n",
       "           [-0.0672, -0.1316, -0.0742]],\n",
       " \n",
       "          [[ 0.0061, -0.0520,  0.0936],\n",
       "           [-0.0465,  0.0880,  0.1009],\n",
       "           [-0.0256,  0.1157, -0.1344]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0099,  0.1294, -0.0386],\n",
       "           [-0.0613, -0.0251,  0.0956],\n",
       "           [ 0.0551,  0.0057,  0.0897]],\n",
       " \n",
       "          [[-0.1316,  0.0296, -0.0528],\n",
       "           [ 0.0880, -0.0214,  0.0895],\n",
       "           [-0.0193,  0.0913,  0.0918]],\n",
       " \n",
       "          [[-0.0070, -0.0590, -0.0848],\n",
       "           [-0.1302, -0.0843, -0.0937],\n",
       "           [ 0.1226,  0.0027,  0.0601]],\n",
       " \n",
       "          [[-0.0551,  0.0896,  0.0681],\n",
       "           [ 0.0623, -0.0455,  0.1313],\n",
       "           [-0.0263,  0.0327,  0.0483]],\n",
       " \n",
       "          [[-0.0279,  0.0505, -0.0784],\n",
       "           [ 0.0878, -0.0834, -0.0471],\n",
       "           [-0.0163,  0.1252,  0.0339]],\n",
       " \n",
       "          [[ 0.1160, -0.0109, -0.0903],\n",
       "           [ 0.1165,  0.0559, -0.0181],\n",
       "           [ 0.0962,  0.0814, -0.0110]]],\n",
       " \n",
       " \n",
       "         [[[-0.0731,  0.0891, -0.1217],\n",
       "           [-0.0963,  0.0240, -0.0242],\n",
       "           [ 0.0561,  0.0287,  0.0356]],\n",
       " \n",
       "          [[-0.0403,  0.0837,  0.1074],\n",
       "           [-0.0991, -0.0868,  0.0777],\n",
       "           [ 0.1233,  0.0823,  0.0635]],\n",
       " \n",
       "          [[ 0.0692, -0.0653,  0.0499],\n",
       "           [-0.1153,  0.0179,  0.1113],\n",
       "           [ 0.1187, -0.0680,  0.0804]],\n",
       " \n",
       "          [[ 0.1040, -0.0509, -0.0262],\n",
       "           [-0.1278,  0.1161,  0.1229],\n",
       "           [ 0.0845,  0.0083,  0.0785]],\n",
       " \n",
       "          [[-0.0956, -0.1110, -0.0592],\n",
       "           [ 0.1185,  0.0482, -0.0177],\n",
       "           [ 0.0354, -0.0907,  0.1084]],\n",
       " \n",
       "          [[-0.0290,  0.0291, -0.0893],\n",
       "           [-0.1340,  0.0012, -0.0941],\n",
       "           [ 0.1103, -0.0564, -0.0708]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0066, -0.1057, -0.0303],\n",
       "           [ 0.0081,  0.0185,  0.0729],\n",
       "           [-0.0482, -0.0977, -0.0412]],\n",
       " \n",
       "          [[ 0.0138, -0.0379,  0.0620],\n",
       "           [-0.0585,  0.0334,  0.1036],\n",
       "           [-0.0567, -0.0677, -0.0507]],\n",
       " \n",
       "          [[-0.0832,  0.1162,  0.0121],\n",
       "           [-0.0990,  0.0253,  0.0136],\n",
       "           [-0.0052, -0.0004,  0.0645]],\n",
       " \n",
       "          [[ 0.0632, -0.0119,  0.0298],\n",
       "           [ 0.0101,  0.0997,  0.0923],\n",
       "           [ 0.0879, -0.0062, -0.0436]],\n",
       " \n",
       "          [[ 0.1277, -0.0277,  0.0920],\n",
       "           [-0.0841,  0.1148, -0.0989],\n",
       "           [ 0.1066,  0.0932, -0.0008]],\n",
       " \n",
       "          [[ 0.0145, -0.0006, -0.0283],\n",
       "           [ 0.0525, -0.1291,  0.1213],\n",
       "           [ 0.0110, -0.0874,  0.1150]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0375, -0.1323,  0.1110],\n",
       "           [-0.0372,  0.0301,  0.0892],\n",
       "           [-0.0734, -0.0013,  0.0574]],\n",
       " \n",
       "          [[ 0.1044,  0.0987, -0.0994],\n",
       "           [-0.1006, -0.0045,  0.0198],\n",
       "           [ 0.0846, -0.1259,  0.0665]],\n",
       " \n",
       "          [[-0.0040, -0.1189,  0.0726],\n",
       "           [-0.1030, -0.0078, -0.0144],\n",
       "           [-0.0153, -0.0178, -0.0804]],\n",
       " \n",
       "          [[ 0.0012,  0.1318, -0.0265],\n",
       "           [ 0.0010,  0.0989,  0.0660],\n",
       "           [-0.0425, -0.1204,  0.1313]],\n",
       " \n",
       "          [[ 0.0918,  0.0042, -0.0520],\n",
       "           [ 0.0155,  0.0853, -0.0969],\n",
       "           [-0.0031, -0.0595,  0.1212]],\n",
       " \n",
       "          [[-0.0522,  0.1030, -0.0040],\n",
       "           [-0.0321,  0.0692,  0.0083],\n",
       "           [-0.0268, -0.1347, -0.0343]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0999,  0.0265,  0.0497, -0.0916, -0.1193, -0.0435,  0.0442, -0.0292,\n",
       "         -0.0449, -0.1333,  0.0883,  0.0943, -0.0718, -0.0835, -0.1295,  0.0563],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0388,  0.0164, -0.0186,  ..., -0.0130, -0.0205, -0.0104],\n",
       "         [ 0.0317,  0.0065, -0.0329,  ...,  0.0044,  0.0394,  0.0230],\n",
       "         [ 0.0403,  0.0022,  0.0317,  ..., -0.0021,  0.0382, -0.0217],\n",
       "         ...,\n",
       "         [-0.0325,  0.0087,  0.0132,  ...,  0.0373,  0.0141, -0.0349],\n",
       "         [-0.0236,  0.0225, -0.0353,  ..., -0.0363,  0.0124,  0.0381],\n",
       "         [ 0.0207, -0.0135, -0.0233,  ...,  0.0118,  0.0246,  0.0040]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0092,  0.0283, -0.0326, -0.0347,  0.0229,  0.0301, -0.0199,  0.0117,\n",
       "         -0.0078,  0.0226, -0.0320, -0.0260,  0.0302, -0.0027,  0.0196,  0.0276,\n",
       "         -0.0405,  0.0284, -0.0136, -0.0016, -0.0307,  0.0399,  0.0193,  0.0023,\n",
       "          0.0248,  0.0334,  0.0412,  0.0415, -0.0243,  0.0315, -0.0201, -0.0409,\n",
       "          0.0129,  0.0241,  0.0398,  0.0177, -0.0351, -0.0275,  0.0081, -0.0195,\n",
       "         -0.0254,  0.0100, -0.0156,  0.0189,  0.0213,  0.0323,  0.0239,  0.0349,\n",
       "         -0.0164, -0.0247,  0.0178, -0.0229, -0.0084,  0.0279, -0.0208,  0.0305,\n",
       "          0.0158,  0.0113,  0.0071, -0.0288, -0.0366,  0.0402, -0.0147,  0.0291,\n",
       "          0.0292,  0.0288, -0.0165,  0.0115,  0.0346,  0.0047, -0.0041,  0.0198,\n",
       "          0.0381,  0.0108,  0.0276, -0.0212,  0.0081,  0.0256,  0.0378, -0.0113,\n",
       "         -0.0170, -0.0261,  0.0157, -0.0232,  0.0279, -0.0215,  0.0058,  0.0202,\n",
       "         -0.0168,  0.0212, -0.0221, -0.0049,  0.0252,  0.0168,  0.0332, -0.0284,\n",
       "         -0.0340, -0.0219, -0.0196, -0.0200, -0.0382, -0.0349,  0.0295,  0.0336,\n",
       "          0.0083,  0.0123, -0.0321,  0.0121,  0.0222, -0.0077,  0.0123,  0.0058,\n",
       "          0.0332, -0.0314, -0.0388, -0.0015,  0.0104, -0.0157, -0.0274, -0.0096],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0018,  0.0398,  0.0667,  ...,  0.0045, -0.0659,  0.0278],\n",
       "         [-0.0400, -0.0054, -0.0101,  ..., -0.0017, -0.0770,  0.0797],\n",
       "         [ 0.0152, -0.0786,  0.0285,  ...,  0.0024,  0.0194,  0.0597],\n",
       "         ...,\n",
       "         [ 0.0863,  0.0372,  0.0889,  ..., -0.0138, -0.0855, -0.0368],\n",
       "         [ 0.0825, -0.0878, -0.0558,  ...,  0.0798, -0.0633,  0.0118],\n",
       "         [-0.0282, -0.0760, -0.0817,  ...,  0.0576, -0.0158,  0.0776]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0449,  0.0676,  0.0296,  0.0613, -0.0725, -0.0510, -0.0611, -0.0257,\n",
       "         -0.0168,  0.0219,  0.0547, -0.0173, -0.0454, -0.0499, -0.0552, -0.0252,\n",
       "         -0.0582,  0.0431, -0.0209, -0.0037,  0.0776,  0.0809, -0.0650,  0.0740,\n",
       "         -0.0870, -0.0102, -0.0301, -0.0609, -0.0610,  0.0109, -0.0839, -0.0247,\n",
       "          0.0221,  0.0174, -0.0603, -0.0694,  0.0615,  0.0060, -0.0488, -0.0873,\n",
       "         -0.0157, -0.0812,  0.0157,  0.0630, -0.0067,  0.0143,  0.0085,  0.0806,\n",
       "         -0.0026,  0.0061, -0.0213, -0.0758, -0.0531, -0.0423, -0.0379,  0.0901,\n",
       "          0.0341, -0.0220,  0.0877,  0.0631,  0.0051, -0.0810,  0.0853, -0.0162,\n",
       "         -0.0533,  0.0193, -0.0553,  0.0042, -0.0231, -0.0705,  0.0213,  0.0644,\n",
       "          0.0570,  0.0906,  0.0066,  0.0442,  0.0132,  0.0827, -0.0564, -0.0489,\n",
       "         -0.0850,  0.0279,  0.0671, -0.0366], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 7.8335e-02, -2.9993e-02, -3.0737e-02, -8.1036e-02,  3.4342e-02,\n",
       "          -1.0269e-01,  1.1129e-02,  8.9239e-02,  3.4377e-02, -1.0408e-01,\n",
       "          -9.5780e-02,  2.9835e-02, -4.4753e-04, -6.7160e-02, -2.8245e-02,\n",
       "           8.0503e-03,  2.5967e-02, -1.8591e-02, -7.6840e-02,  6.7266e-02,\n",
       "          -3.1568e-02,  9.4715e-02,  2.6832e-03, -3.5317e-02,  4.2822e-02,\n",
       "          -1.0687e-01, -4.3304e-02, -6.5161e-02,  1.0449e-01, -3.2534e-02,\n",
       "           9.3426e-02,  8.0644e-03,  6.0251e-02, -6.1376e-02,  2.1464e-02,\n",
       "          -1.0859e-01,  3.8576e-02, -3.4289e-02, -7.9376e-02, -6.7137e-02,\n",
       "          -1.1840e-02, -3.3173e-02, -6.4218e-02, -2.3446e-02, -3.7803e-02,\n",
       "           6.5914e-02, -7.7161e-02,  3.6413e-03, -4.1074e-02,  9.2761e-02,\n",
       "          -2.0892e-02, -8.6495e-02, -5.4541e-02, -5.1879e-02, -4.4294e-02,\n",
       "           6.4238e-02,  6.0563e-02,  9.6911e-02, -5.8455e-02,  4.4072e-02,\n",
       "          -4.7258e-02,  3.4635e-02, -3.9645e-02,  1.0407e-01,  6.1600e-02,\n",
       "           1.0617e-01,  3.0121e-02, -3.2685e-02,  2.3593e-03, -1.0600e-01,\n",
       "          -1.0543e-01,  8.0878e-02, -9.4891e-02, -1.0318e-01, -4.0588e-02,\n",
       "          -4.8496e-02, -5.6681e-03,  2.5040e-02, -1.0383e-01,  7.0924e-03,\n",
       "           9.7619e-02, -4.2846e-02,  9.0935e-03,  1.8805e-02],\n",
       "         [ 2.8131e-02,  9.0647e-02, -8.5481e-02,  8.5517e-02, -2.8972e-02,\n",
       "           7.1276e-02,  7.9951e-02, -8.7564e-02,  1.0197e-01,  5.2003e-02,\n",
       "          -2.9537e-02, -9.8737e-02, -2.5888e-02,  7.5971e-03,  3.8312e-02,\n",
       "           8.3144e-03, -1.0723e-01, -3.0024e-02,  5.6310e-03, -1.7898e-02,\n",
       "           4.9330e-02, -4.7627e-02, -3.1152e-02,  4.0151e-02,  1.8443e-03,\n",
       "           7.5897e-02, -8.6982e-02, -5.9894e-02, -1.0853e-01,  8.6896e-02,\n",
       "          -2.1791e-02,  2.3998e-02,  3.4082e-02, -7.5834e-02,  9.2163e-02,\n",
       "           8.1235e-02,  1.0506e-01, -8.8875e-02,  2.9236e-03,  9.5674e-02,\n",
       "          -5.3560e-02, -4.0868e-02,  8.3784e-02,  1.0681e-01, -2.2273e-02,\n",
       "          -1.0779e-01,  4.5010e-02,  1.5898e-02, -3.6779e-02,  4.8745e-02,\n",
       "           8.2786e-02,  6.2662e-02,  9.1847e-03, -1.0082e-01,  5.5030e-02,\n",
       "          -3.6162e-02, -8.7471e-02,  3.0997e-02, -8.2038e-02,  4.4471e-02,\n",
       "           7.5639e-02,  7.5766e-03, -7.7057e-02, -3.2782e-02, -6.9280e-02,\n",
       "           4.9680e-02, -6.4941e-02,  8.5799e-03,  6.8434e-02, -1.8942e-03,\n",
       "          -8.8336e-03, -2.1336e-02, -7.8488e-02,  1.9759e-02,  2.2616e-02,\n",
       "          -4.2325e-02, -2.1717e-02,  8.9004e-02, -1.0108e-02,  4.2241e-02,\n",
       "           1.8333e-02,  8.8955e-02,  6.7539e-02,  4.5946e-03],\n",
       "         [-1.9956e-02,  8.1632e-02,  5.7076e-02,  3.4801e-02, -6.4682e-02,\n",
       "          -5.9459e-02,  4.9486e-02,  4.8629e-02,  5.2095e-02,  9.8172e-02,\n",
       "           9.6307e-02,  9.7657e-02, -9.0600e-02,  6.5583e-03, -1.0584e-01,\n",
       "          -7.4988e-02,  2.0184e-02,  1.0092e-02,  8.8760e-03, -2.9796e-02,\n",
       "           2.6632e-02,  4.3064e-02, -1.0504e-01, -7.0325e-02,  1.0682e-02,\n",
       "           5.4376e-02, -2.4931e-02,  3.4931e-02, -4.5978e-02, -1.4124e-02,\n",
       "           7.7578e-02,  6.4898e-02, -5.4562e-02,  5.0958e-02, -9.8863e-02,\n",
       "           3.4704e-02, -1.0838e-01, -3.4436e-02, -6.3325e-02,  7.8831e-02,\n",
       "          -2.1952e-04,  1.4504e-02, -6.9621e-03, -7.0667e-02, -4.3204e-02,\n",
       "           1.3488e-02, -7.9683e-02,  9.7815e-02, -1.6795e-02,  3.5663e-02,\n",
       "          -4.6777e-02,  1.1936e-02, -8.5762e-02, -7.2226e-02,  1.8793e-02,\n",
       "           2.5470e-02, -6.6528e-02, -1.7608e-02,  1.0819e-01, -7.5070e-02,\n",
       "           6.9361e-02, -6.0274e-02,  7.6068e-02, -3.4297e-02,  2.2406e-02,\n",
       "           1.7833e-03,  2.0073e-02, -4.4746e-02, -3.4212e-02,  4.0223e-02,\n",
       "          -9.0445e-02,  9.4442e-02, -4.0900e-02, -6.2452e-03, -6.8723e-02,\n",
       "          -7.9721e-03,  1.3335e-02,  5.2226e-02, -1.0526e-01, -7.0108e-02,\n",
       "           1.9760e-02,  9.3263e-02,  1.6903e-03,  1.0418e-02],\n",
       "         [-7.3256e-02, -8.8338e-02, -3.0306e-03,  3.3355e-02,  6.4966e-02,\n",
       "          -7.6367e-02, -7.5581e-02,  4.0944e-02, -1.7011e-02, -2.6987e-03,\n",
       "           2.1475e-03, -8.7838e-02,  1.5114e-02, -3.3353e-02, -8.0631e-02,\n",
       "          -9.4435e-02,  6.4998e-02, -6.0157e-02, -7.7593e-02, -8.9390e-02,\n",
       "          -5.3128e-02,  1.3497e-02,  7.5702e-02,  3.8444e-02, -2.7215e-02,\n",
       "          -9.2008e-02,  1.0434e-01, -1.5332e-02, -6.8770e-02, -4.4466e-02,\n",
       "          -3.0445e-02, -9.2362e-03, -8.6911e-03,  1.4726e-02,  7.7394e-02,\n",
       "           1.0664e-01, -2.4745e-02, -9.1243e-02,  5.2792e-02, -7.8753e-02,\n",
       "          -3.9354e-02, -3.6868e-02, -5.2114e-02,  5.4436e-03,  7.4072e-02,\n",
       "          -5.0158e-02, -3.2616e-02,  9.6370e-02,  9.7427e-02, -7.2149e-02,\n",
       "           7.4089e-05,  3.9459e-02, -4.2414e-02,  3.8957e-02,  8.5593e-02,\n",
       "          -1.6176e-02, -3.9020e-04,  7.6239e-02,  3.0330e-02, -1.1811e-02,\n",
       "          -3.5855e-02, -1.3598e-02,  8.8426e-02, -5.5061e-02, -8.8863e-02,\n",
       "           2.7889e-02, -5.8162e-03,  3.2785e-02, -8.5040e-02,  1.5924e-02,\n",
       "           3.1845e-02,  6.9583e-02,  4.0391e-02,  7.6852e-02,  2.6313e-02,\n",
       "           4.4500e-02, -9.8967e-03, -7.3790e-02,  7.3434e-03, -9.4691e-02,\n",
       "           9.7287e-02, -1.1055e-02,  3.2672e-02, -9.9209e-02],\n",
       "         [-6.6723e-02,  9.3360e-02,  9.7100e-02,  1.6748e-02,  2.1760e-02,\n",
       "          -8.5550e-02, -6.6453e-02,  3.3686e-02, -1.0794e-01,  8.5806e-02,\n",
       "          -6.5424e-02,  1.0912e-03,  5.0695e-02, -4.2773e-02,  7.2870e-02,\n",
       "          -9.9018e-02, -2.0402e-02, -1.0150e-01, -5.3942e-02,  6.4697e-02,\n",
       "          -5.4998e-02, -8.8745e-02,  4.9314e-02,  6.6204e-02,  4.2823e-02,\n",
       "          -1.9270e-02,  6.3172e-02,  7.3776e-02,  3.1992e-02,  1.9673e-02,\n",
       "          -6.0135e-02, -6.0441e-02, -3.0829e-03,  1.9305e-02,  7.0365e-02,\n",
       "          -8.6102e-02, -4.1260e-02,  6.9902e-02,  2.8648e-03,  5.6261e-02,\n",
       "           6.0367e-02, -4.4986e-03, -1.0543e-01, -1.0467e-01,  1.6368e-02,\n",
       "          -9.4385e-02, -4.8933e-02, -1.3411e-02, -9.4228e-02, -2.4640e-02,\n",
       "          -8.5246e-02, -4.1317e-02,  4.6370e-03,  1.6820e-02, -3.1156e-02,\n",
       "          -2.3290e-02,  8.5541e-03,  6.0097e-02, -5.1682e-02,  1.0075e-01,\n",
       "          -2.3863e-02, -7.4585e-02, -9.5655e-02,  7.3991e-03, -1.0966e-03,\n",
       "          -1.0182e-01,  3.0830e-02, -1.1601e-02,  5.2692e-02,  8.3705e-02,\n",
       "          -5.0738e-02, -9.4173e-02, -2.1744e-02,  9.2917e-02,  7.4608e-02,\n",
       "          -9.0852e-02,  4.1378e-02, -1.0419e-01,  5.3469e-02, -7.0103e-02,\n",
       "           6.9376e-03, -1.0218e-01,  6.8688e-02,  4.4040e-02],\n",
       "         [-4.7782e-02, -6.6919e-02, -7.6838e-02,  1.7852e-02, -8.9775e-03,\n",
       "          -3.4150e-02, -5.1176e-02,  4.7107e-02, -3.9018e-02, -4.9365e-02,\n",
       "           2.5930e-02,  9.7931e-02, -7.8502e-02, -6.5445e-02,  3.7573e-02,\n",
       "          -8.6296e-02, -7.1007e-02, -7.1707e-02, -9.6446e-02, -2.5258e-02,\n",
       "           1.4040e-02, -2.5471e-02,  7.5671e-04, -2.5107e-02, -1.0252e-01,\n",
       "           2.0386e-02, -7.3122e-02,  4.1604e-02, -6.9772e-02,  2.7605e-02,\n",
       "          -1.0147e-02,  1.1108e-02,  1.4866e-02, -9.4013e-02, -7.9452e-02,\n",
       "           1.5947e-02, -4.7947e-02,  5.5353e-02,  9.6203e-02,  3.3715e-03,\n",
       "          -4.9478e-02, -2.3166e-02, -5.1218e-02, -7.5154e-02, -9.0199e-02,\n",
       "           8.0170e-02,  2.3815e-02,  1.0119e-01, -5.5562e-02,  1.4660e-02,\n",
       "          -5.2716e-02,  1.7902e-02,  7.1470e-02,  5.4039e-02, -8.5857e-02,\n",
       "          -4.9275e-02, -2.2242e-02,  1.7642e-03,  3.1310e-02, -7.9508e-02,\n",
       "          -7.6431e-02, -8.2146e-02, -1.6900e-02,  7.1550e-02, -8.3525e-02,\n",
       "          -9.4023e-03, -9.9816e-02,  8.3462e-02, -5.6906e-02, -8.0434e-02,\n",
       "          -2.7049e-02,  5.7219e-02,  8.1932e-02, -1.7859e-02,  5.9117e-02,\n",
       "          -1.9079e-02,  7.3760e-02,  6.7893e-02, -8.4327e-02, -3.6961e-02,\n",
       "           4.8355e-03, -1.0579e-01, -7.3971e-02,  7.4405e-02],\n",
       "         [ 8.8599e-02,  9.2551e-02,  8.1154e-02,  9.9915e-02,  1.0005e-01,\n",
       "          -9.7232e-02, -6.0157e-02, -8.9552e-02,  8.7685e-02,  3.9589e-02,\n",
       "           1.0066e-01, -6.5025e-02, -3.3162e-02,  3.2932e-02, -9.6680e-02,\n",
       "          -1.2219e-02,  7.4804e-02,  2.9125e-02, -8.2646e-02,  1.0238e-01,\n",
       "          -5.6739e-03,  1.0253e-01, -1.0428e-01, -1.3176e-02,  1.0883e-01,\n",
       "          -2.5649e-03, -5.1123e-02, -5.1121e-04, -5.3807e-02, -3.6835e-02,\n",
       "           2.9221e-02,  7.6172e-03, -1.5771e-02,  5.9055e-02,  7.9069e-02,\n",
       "          -4.5241e-02,  8.1223e-02, -1.0786e-01, -5.5028e-02,  6.9640e-02,\n",
       "          -6.1104e-02,  2.0856e-02,  1.0441e-01, -9.0438e-02,  4.5814e-02,\n",
       "           1.0548e-01, -7.1344e-02, -7.6582e-02,  1.0190e-01,  1.0082e-01,\n",
       "          -5.3896e-02,  2.2271e-02,  9.7821e-02,  1.2314e-02, -6.4623e-02,\n",
       "           1.0635e-01, -2.7246e-02,  7.9274e-03, -9.6208e-02,  9.2860e-02,\n",
       "           4.3617e-02,  8.7336e-02, -8.6700e-02, -6.8592e-02, -5.9720e-02,\n",
       "          -1.8903e-02, -7.5531e-03, -6.5607e-02,  7.7064e-02,  1.3671e-02,\n",
       "           8.5834e-02,  5.2056e-02, -1.0478e-01, -7.5498e-02,  5.7711e-03,\n",
       "           3.2794e-03, -4.4525e-02,  5.3039e-02, -6.6778e-02, -9.8149e-02,\n",
       "          -3.7188e-02,  1.1082e-03, -7.5907e-02, -3.9496e-03],\n",
       "         [ 5.1683e-02, -1.0488e-01,  5.5910e-02,  4.7917e-02,  5.1914e-02,\n",
       "           7.1817e-02,  8.7933e-02, -9.1847e-03, -7.1337e-02, -4.4460e-02,\n",
       "           1.4141e-03,  3.3912e-03, -7.8680e-04,  1.8250e-02,  9.7748e-02,\n",
       "           4.9817e-02,  8.8869e-02, -5.2230e-02, -2.2582e-02, -4.0855e-02,\n",
       "           5.3588e-02, -6.4864e-02, -3.4630e-02,  5.9993e-02, -3.7695e-02,\n",
       "          -8.2660e-02,  5.4022e-02, -7.8945e-02,  8.9158e-02, -4.2451e-03,\n",
       "          -9.5735e-02, -6.3261e-02, -3.7418e-02, -6.6946e-02, -3.8624e-03,\n",
       "          -5.2883e-02,  2.7446e-02,  6.8202e-02, -2.7582e-02, -1.0385e-01,\n",
       "           5.1424e-02,  7.0899e-02,  2.2506e-02, -3.6853e-02, -8.8269e-03,\n",
       "          -1.5792e-02,  7.7857e-02,  2.5112e-03, -1.3786e-02, -5.2231e-02,\n",
       "          -7.7093e-02, -6.0015e-02,  1.0318e-01,  9.1608e-02,  6.7038e-02,\n",
       "          -2.6954e-02,  6.8630e-02,  7.8798e-02,  1.4671e-03, -4.1756e-02,\n",
       "          -7.6770e-02, -5.5017e-02,  2.9611e-02, -1.9955e-02, -9.5874e-02,\n",
       "           7.6807e-02, -1.5881e-02,  7.7652e-02, -5.0397e-02, -6.8145e-02,\n",
       "          -2.6734e-02, -8.9330e-02,  8.5617e-02,  1.0069e-01,  9.8847e-02,\n",
       "           9.4151e-02,  8.6258e-02,  9.6143e-02, -1.0158e-01,  1.3912e-02,\n",
       "          -4.6390e-02,  3.5821e-02,  3.9693e-02, -7.4805e-02],\n",
       "         [-7.6566e-02, -4.1164e-02, -5.0985e-02, -9.5740e-02,  9.9524e-03,\n",
       "          -6.4676e-02,  1.8085e-02,  3.6638e-02,  7.1283e-02,  1.0807e-01,\n",
       "           6.3807e-03, -8.1285e-02,  2.4326e-02,  2.7746e-03,  3.9996e-02,\n",
       "          -6.1480e-02,  1.8778e-02,  7.4976e-02,  9.7237e-02,  2.7972e-02,\n",
       "          -1.0516e-01,  9.4122e-02, -1.0131e-01,  8.5103e-03,  4.4704e-02,\n",
       "           6.9123e-02,  7.4507e-02, -1.0771e-01, -1.0722e-01,  4.8890e-02,\n",
       "          -7.5136e-02, -1.0647e-01, -7.5946e-02, -6.9702e-02, -9.9664e-02,\n",
       "           3.5704e-02, -4.1919e-02, -9.9326e-02,  6.3143e-02,  5.5655e-02,\n",
       "           1.5673e-02, -9.1427e-02, -3.7097e-02,  8.4721e-02, -9.5679e-02,\n",
       "           6.4804e-02,  7.2996e-02, -3.6610e-02,  6.6952e-02, -6.2265e-02,\n",
       "          -5.2997e-02, -1.0447e-02, -1.3463e-02,  7.3420e-02, -7.6685e-02,\n",
       "           3.8045e-03, -6.2351e-02,  1.0212e-01, -9.2916e-02, -7.5148e-02,\n",
       "           2.8829e-02, -8.7325e-02, -7.1093e-02,  1.0473e-01,  5.4051e-02,\n",
       "          -2.1280e-02,  2.2292e-02, -3.5542e-02, -7.1644e-02, -4.9766e-02,\n",
       "          -8.1141e-02,  4.4919e-02, -4.7885e-02, -5.2322e-02, -2.0669e-02,\n",
       "           2.7256e-02,  4.5810e-02,  3.7029e-02, -6.1587e-03, -1.6907e-02,\n",
       "          -1.0266e-01, -1.5942e-02, -5.6047e-02, -4.3083e-02],\n",
       "         [-8.7871e-02, -5.1722e-02,  3.7701e-02,  5.2501e-02, -9.5144e-02,\n",
       "          -5.8529e-02, -9.6585e-02,  2.7352e-02, -8.6471e-02, -6.4615e-02,\n",
       "          -6.5577e-02, -8.2167e-02,  9.4961e-02,  5.4884e-03, -9.4720e-02,\n",
       "          -5.8700e-03, -9.5950e-02, -8.0847e-03, -3.9145e-02, -6.4073e-02,\n",
       "           5.1788e-02,  6.1475e-02, -8.4030e-02,  2.1151e-02,  3.6348e-02,\n",
       "          -1.7678e-02,  1.0325e-01, -6.6210e-02, -5.1150e-02, -7.4746e-02,\n",
       "           4.9812e-02, -6.0870e-02, -4.2202e-02, -8.2606e-02,  3.6275e-03,\n",
       "           8.5284e-02,  9.5848e-02, -6.6614e-02,  5.2931e-02,  8.9750e-02,\n",
       "          -5.4008e-03, -6.1058e-02, -1.5786e-02, -8.9569e-02,  4.9316e-02,\n",
       "           6.8934e-02,  5.2873e-03,  2.9226e-04, -9.1065e-02,  1.0723e-01,\n",
       "           6.7440e-02,  3.5197e-03, -1.0448e-01, -7.6999e-02,  7.5798e-02,\n",
       "          -9.4825e-04, -1.0513e-01,  2.2588e-02,  2.3347e-02,  2.6159e-02,\n",
       "          -3.7757e-02,  1.4482e-02,  1.0589e-01, -4.3579e-02,  1.5320e-02,\n",
       "           3.5441e-02,  4.8591e-02, -8.8174e-02, -5.3949e-02, -4.9945e-03,\n",
       "           4.7945e-03,  2.2811e-02,  3.2860e-02,  1.0391e-01, -9.0440e-03,\n",
       "           6.7008e-02, -5.8217e-02, -9.8622e-02,  2.1239e-02,  1.5906e-02,\n",
       "          -7.7307e-02, -5.8153e-02, -6.4115e-02, -1.0377e-01]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0765, -0.0469,  0.0264,  0.0455,  0.0774,  0.0320,  0.0465,  0.0568,\n",
       "          0.0536,  0.0864], requires_grad=True)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1205, -0.0728,  0.1330,  0.0376,  0.0162,  0.0004,  0.0938,  0.0316,\n",
      "          0.0281,  0.0968]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1,1,32,32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward(torch.rand(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2047, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x7fa24da2fc50>\n",
      "<AddmmBackward object at 0x7fa24da2fcf8>\n",
      "<AccumulateGrad object at 0x7fa24da2fc50>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0103, -0.0104,  0.0141, -0.0144, -0.0025, -0.0217])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
